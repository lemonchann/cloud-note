摘选马克问答

我先关注，尝试慢慢从一些方面去回答你问题中的一部分。

2、怎么防止机器人秒杀？
（1）邀请码，提前将邀请码发送给选中的用户，比如曾经购买过该商品的用户。
（2）手机验证码，每轮秒杀开始前都要填写手机号，获取验证码，一个验证码只能用于一轮秒杀。
（3）各种防机器人的验证码登录校验都可以作为秒杀开始的前奏，补图（网易邮箱、知乎）、答题（QQ加好友）、选择物品（12306）通过后进入秒杀。
题主没有限制，我也就枚举一下日常常见的方式，方式非常多。

3、怎么保证秒杀的公平且可见？
没有绝对的公平，类似于12306中显示当前排队人数，剩余票数，保证了可见性，在公平性上对于购买者有极大的心理安慰作用，至于数据是否是真实的，后台有没有骚操作，我们不得而知，由他们的价值观保证，看他们是否瑞雪。

4、怎么处理缓存和落地数据的一致性？
这个问题应该延伸一下，怎么保证不超卖，库存不为负数，红包金额不为负，并且所有红包要等于总金额，账能对齐。最核心的问题。这应该是秒杀功能设计、秒杀业务逻辑设计和编码实现要重点关注的问题，并且还要重点Review扣库存的代码。

1、怎么进行压测和验证设计的秒杀系统是否过关？
根据我之前负责618和双十一全链路压测的经验，和你分享下压测相关事项。首先确保压测数据和真实的生产数据分开，必须带上压测标，每次压测产生千万、上亿或者几十亿的数据，一般都要经历3轮以上的压测，压测数据和生产数据不分开，后续表的数据量太大，影响DB吞吐量。

你必须准备至少两套工具，一套是压测平台，一套是流量回放平台，用于压测过程中发现的问题排查定位

你还要准备压测脚本，根据秒杀算法和业务逻辑，脚本中必须包含对单接口的压测，对链路的压测，单接口比较好说，复杂的是链路，为了好说明问题，我将链路拆分成几个阶段，下单、支付、扣库存、出库、发货。。。

5、怎么保证TPS？
秒杀系统，是典型的短时大量突发访问类问题。系统要能抗住并发，需要软硬结合。对这类问题，有三种优化性能的思路：写入内存而不是写入硬盘、异步处理而不是同步处理、分布式协同处理。

SSD硬盘比传统硬盘快100倍，而内存又比SSD硬盘快10倍以上。因此写入内存而不是写入硬盘，就能使系统的能力提升上千倍。你可能会有这样的疑问：写入内存而不是持久化，那么如果此时计算机宕机了，那么写入的数据不就全部丢失了吗？Redis Cluster多台机器，并且Redis RDB、AOF可以对数据进行持久化，足以满足6个9的可用性和稳定性。

异步处理而不是同步处理，像秒杀这样短时大并发的系统，在性能负载上有一个明显的波峰和长期的波谷。为了应对相当短时间的大并发而准备大量服务器来应对，在经济上是相当不合算的。 因此，对付秒杀类需求，就应该化同步为异步。用户请求写入内存后立刻返回，后台启动多个线程从内存池中异步读取数据，进行处理。

分布式处理 ，也许你的客户很多，秒杀系统即使用了上面两招，还是捉襟见肘，如果一台服务器撑不住秒杀系统，那么就多用几台服务器，10台不行，就上100台。分布式处理，对用户id、手机号、IP使用hash实现均匀分布。

有着三招，抗住并发肯定是不成问题的。

8、秒杀类架构探讨
和秒杀类似的，还有抢购、抢票、红包、抽奖。。。等场景。特点都是瞬时高并发、操作幂等、防作弊、先到先得的公平性。

对于瞬间高并发
（1）服务方面，如果并发太大，你无法准确预估，也不能无限的加机器，那么你必须对你的服务做好过载保护，比如：
接口限流（单接口限流和总流量限流），
服务降级（比如当某个接口响应时间超过阈值，立即返回，不再继续占用资源），
服务熔断（比如某个非核心服务，商品详情页，在系统并发量超过阈值的时候，商品详情服务直接下线）、
服务隔离（比如下单、支付服务一定是和商品详情分开的，下单、支付才是核心，必须确保）

（2）如果还是请求过大，并且这些请求你都不能丢，比如12306抢票，那么也还是有办法的
我们可以让请求排队，组成请求队列，所有用户的请求过来，将请求参数等相关信息组装成对象存入Redis或者Kafka，然后立马返回，让用户稍后查看结果。后续再对队列中的请求逐个处理，将处理的结果和请求对象关联，用户刷新后就能查看到结果。对同一个请求我们还要做好幂等处理。

队列化，能大大减轻瞬间压力，实现削峰填谷，利用多线程，实现异步化，避免因单个任务周期长而影响整个队列的处理速度。

（3）**服务架构设计，千万不能忘记服务之间的解耦，现在微服务、Service Mesh、Cloud Native、Serverless各种新概念和新技术层出不穷，服务治理的手段多种多样**，但一套具有高可扩展性高稳定性的服务架构离不开服务之间的解耦，试想服务都耦合在一起，对于改动升级，一个点带动一条线，一条线带动整个服务体系，那么这样的服务架构的稳定性能难以保证，或者为了保证耦合在一起的服务的稳定性，我们需要投入巨大的成本。
既然服务解耦这么重要，那么是不是在各微服务之间用类似于Kafka消息组件就能解耦呢，不错Kafka提供了技术上的解耦，但真正的解耦应该是业务和技术结合在一起做，让业务尽可能的原子化，高内聚低耦合，技术依赖尽可能消息化。比如订单系统，支付系统，物流系统，订单可以是淘宝天猫京东的，支付可以是微信支付宝银行卡，物流可以是顺丰京东四通一达，这三套系统必须内聚，并且绝对没有数据库、Redis、RPC接口强依赖关系。这就是为什么阿里一定会自研消息系统，因为阿里的业务系统太庞大，业务之间的依赖太多，如果不是业务系统的内聚和消息系统来解耦，那么服务之间的依赖关系变得不可维护。

**由此我们总结几个关键字：
过载保护、接口限流、服务降级、服务熔断、服务隔离、服务解耦、请求队列、削峰填谷、多线程异步化、接口幂等**

（3）数据存储方面
尽量选用偏内存型高吞吐量的组件，**如Memcached、Redis、LevelDB、RocksDB。。。**
对于数据的保存，选择“小步快跑”方式，一次性操作很多记录会造成资源短时间无法释放，严重影响并发性能。
有的同学可能觉得，怎么简单怎么写，选择合适的经过优化的算法也非常重要。

系统高可用
（1）现在的系统绝大部分都是分布式的，一套完整的系统都是由很多服务来协同完成的。为了保证服务高可用，Java系统往往采用Nginx(多个Upstream) + Tomcat(Docker化)多实例的集群模式来保证当前服务的可用性和负载均衡。
为了避免Nginx成为单点，我们可以用Nginx + Keepalived来实现至少一主一备的架构来保证服务的4个9甚至5个9的可用性。
对服务，我们还可以对服务节点做健康检查，做到故障及时重启，Nginx对不健康的节点及时剔除。

（2）网络层，我们也要保证高可用，动态DNS不能丢。
DNS这么老的技术，或者现在云平台已经很成熟了，还需要DNS吗？需要，肯定是需要的。DNS对于异地多活和灾备有非常大的作用，可以说是必须的。